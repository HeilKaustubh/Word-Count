import org.apache.spark.{SparkConf, SparkContext}

object WordCount {
  System.setProperty("hadoop.home.dir", "C:\\Users\\xx\\Downloads\\Hadoop\\")

  def main(args: Array[String]): Unit ={
    val conf = new SparkConf().setAppName("Word Count").setMaster("local")
    val sc = new SparkContext(conf)
    val input = sc.textFile("C:\\Users\\xx\\IdeaProjects\\HelloScala\\src\\main\\scala\\kk.txt")
    val count = input.flatMap(line=>line.split(" "))
      .map(word=>(word,1))
      .reduceByKey(_+_)
    count.saveAsTextFile("C:\\Users\\xx\\Downloads\\SparkTest5")
    System.out.println("Scala Spark Works!")
  }
}
